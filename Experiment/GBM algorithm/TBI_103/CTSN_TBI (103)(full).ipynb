{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079e5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e12cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\CTSN_TBI\\Machine_learning\\GBM algorithm\n",
      "F:\\CTSN_TBI\\Machine_learning\\GBM algorithm\\TBI_data_2.csv\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "print(os.getcwd())\n",
    "\n",
    "data_link = os.getcwd() + \"\\\\TBI_data_2.csv\"\n",
    "print(data_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b289d521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Data columns (total 70 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   record_id                                     260 non-null    int64  \n",
      " 1   age_at_record                                 259 non-null    float64\n",
      " 2   sex                                           259 non-null    float64\n",
      " 3   tbi_cli_reason                                259 non-null    float64\n",
      " 4   tbi_cli_time_acci_hos                         240 non-null    float64\n",
      " 5   tbi_cli_pulse                                 84 non-null     float64\n",
      " 6   tbi_cli_temp                                  84 non-null     float64\n",
      " 7   tbi_cli_blood_pressure                        83 non-null     float64\n",
      " 8   tbi_cli_breathing_rate                        30 non-null     float64\n",
      " 9   tbi_cli_glasgow                               260 non-null    int64  \n",
      " 10  tbi_cli_awaken                                258 non-null    float64\n",
      " 11  tbi_cli_headache                              250 non-null    float64\n",
      " 12  tbi_cli_blue                                  251 non-null    float64\n",
      " 13  tbi_cli_para_ner                              252 non-null    float64\n",
      " 14  tbi_cli_quadriplegia                          254 non-null    float64\n",
      " 15  tbi_cli_epileptic                             253 non-null    float64\n",
      " 16  tbi_cli_stiff_neck                            254 non-null    float64\n",
      " 17  tbi_cli_dam_chest_abdomen                     255 non-null    float64\n",
      " 18  tbi_cli_recall                                249 non-null    float64\n",
      " 19  tbi_cli_pupils_left_size                      259 non-null    float64\n",
      " 20  tbi_cli_pupils_left_reflex                    260 non-null    int64  \n",
      " 21  tbi_cli_pupils_right_size                     258 non-null    float64\n",
      " 22  tbi_cli_pupils_right_reflex                   258 non-null    float64\n",
      " 23  tbi_cli_diabetes                              248 non-null    float64\n",
      " 24  tbi_cli_hypertension                          232 non-null    float64\n",
      " 25  tbi_cli_stroke                                230 non-null    float64\n",
      " 26  tbi_cli_cardiovascular                        228 non-null    float64\n",
      " 27  tbi_ct_brain_parenchyma___1                   260 non-null    int64  \n",
      " 28  tbi_ct_brain_parenchyma___2                   260 non-null    int64  \n",
      " 29  tbi_ct_brain_parenchyma___3                   260 non-null    int64  \n",
      " 30  tbi_ct_brain_parenchyma___4                   260 non-null    int64  \n",
      " 31  tbi_ct_brain_parenchyma___5                   260 non-null    int64  \n",
      " 32  tbi_ct_brain_parenchyma___6                   260 non-null    int64  \n",
      " 33  tbi_ct_brain_parenchyma___7                   260 non-null    int64  \n",
      " 34  tbi_ct_brain_parenchyma___8                   260 non-null    int64  \n",
      " 35  tbi_ct_brain_parenchyma___9                   260 non-null    int64  \n",
      " 36  tbi_ct_brain_parenchyma___10                  260 non-null    int64  \n",
      " 37  tbi_ct_brain_parenchyma___11                  260 non-null    int64  \n",
      " 38  tbi_ct_brain_parenchyma___12                  260 non-null    int64  \n",
      " 39  tbi_ct_epidural_hematoma_volume               41 non-null     float64\n",
      " 40  tbi_ct_epidural_hematoma_proportion           42 non-null     float64\n",
      " 41  tbi_ct_epidural_hematoma_value                40 non-null     float64\n",
      " 42  tbi_ct_subdural_hematoma_thick                93 non-null     float64\n",
      " 43  tbi_ct_subdural_hematoma_position_proprotion  96 non-null     float64\n",
      " 44  tbi_ct_subdural_hematoma_position_value       79 non-null     float64\n",
      " 45  tbi_ct_cerebral_contusion_volume              78 non-null     float64\n",
      " 46  tbi_ct_blood_hematoma_volume                  11 non-null     float64\n",
      " 47  tbi_ct_blood_hematoma_proportion              12 non-null     float64\n",
      " 48  tbi_ct_blood_hematoma_value                   10 non-null     float64\n",
      " 49  tbi_ct_subarachnoid_characteristic            112 non-null    float64\n",
      " 50  tbi_ct_midline_shift_width                    5 non-null      float64\n",
      " 51  tbi_ct_bottom_tank_characteristic             6 non-null      float64\n",
      " 52  tbi_ct_skull_fracture_characteristic          79 non-null     float64\n",
      " 53  tbi_ct_skull_risk                             252 non-null    float64\n",
      " 54  tbi_ct_rotterdam                              252 non-null    float64\n",
      " 55  hong_cau_v2                                   257 non-null    float64\n",
      " 56  bach_cau_v2                                   257 non-null    float64\n",
      " 57  tieu_cau_v2                                   257 non-null    float64\n",
      " 58  d_1_hst                                       251 non-null    float64\n",
      " 59  ethanol                                       109 non-null    float64\n",
      " 60  ast_v2                                        257 non-null    float64\n",
      " 61  alt_v2                                        255 non-null    float64\n",
      " 62  d_2_protein                                   214 non-null    float64\n",
      " 63  albumin_v2                                    175 non-null    float64\n",
      " 64  ure_v2                                        257 non-null    float64\n",
      " 65  creatinin_v2                                  257 non-null    float64\n",
      " 66  prothrombin_v2                                247 non-null    float64\n",
      " 67  d_3_aptt                                      244 non-null    float64\n",
      " 68  d_4_dtim                                      193 non-null    float64\n",
      " 69  d_kl_tl                                       260 non-null    int64  \n",
      "dtypes: float64(54), int64(16)\n",
      "memory usage: 142.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_tbi = pd.read_csv(data_link, delimiter = \",\")\n",
    "df_tbi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094c22e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.804484</td>\n",
       "      <td>0.402031</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.194118</td>\n",
       "      <td>-0.792786</td>\n",
       "      <td>-0.795610</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>3.152380</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.792256</td>\n",
       "      <td>1.489632</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>4.288194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.134370</td>\n",
       "      <td>0.442006</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>2.066500</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>3.152380</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.767799</td>\n",
       "      <td>-0.307274</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.074964</td>\n",
       "      <td>-0.383072</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>-0.251070</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.755571</td>\n",
       "      <td>1.064049</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.322489</td>\n",
       "      <td>-0.795610</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>0.326810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>2.429655</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.743342</td>\n",
       "      <td>-1.111153</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.182502</td>\n",
       "      <td>0.618104</td>\n",
       "      <td>0.442006</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>-0.251070</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.643916</td>\n",
       "      <td>-1.016579</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>4.288194</td>\n",
       "      <td>-0.194118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>2.060315</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>1.486784</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1.656145</td>\n",
       "      <td>-0.165413</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.194118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.745643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>1.486784</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>0.870373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.668373</td>\n",
       "      <td>1.915215</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>8.157150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>2.060315</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>1.486784</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>0.870373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.680602</td>\n",
       "      <td>0.023735</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.176695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1.692830</td>\n",
       "      <td>-0.023552</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.188310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0   -1.804484  0.402031 -0.578836 -0.421243 -0.194118 -0.792786 -0.795610   \n",
       "1   -1.792256  1.489632 -0.578836  4.288194       NaN -0.134370  0.442006   \n",
       "2   -1.767799 -0.307274 -0.578836 -0.421243       NaN -1.074964 -0.383072   \n",
       "3   -1.755571  1.064049 -0.578836 -0.421243       NaN -0.322489 -0.795610   \n",
       "4   -1.743342 -1.111153 -0.578836 -0.421243 -0.182502  0.618104  0.442006   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "255  1.643916 -1.016579 -0.578836  4.288194 -0.194118       NaN       NaN   \n",
       "256  1.656145 -0.165413 -0.578836 -0.421243 -0.194118       NaN       NaN   \n",
       "257  1.668373  1.915215 -0.578836 -0.421243  8.157150       NaN       NaN   \n",
       "258  1.680602  0.023735 -0.578836 -0.421243 -0.176695       NaN       NaN   \n",
       "259  1.692830 -0.023552 -0.578836 -0.421243 -0.188310       NaN       NaN   \n",
       "\n",
       "           7         8         9   ...        60        61        62  \\\n",
       "0   -0.370117  0.328322 -0.018599  ...  1.128865  1.802776 -0.411581   \n",
       "1   -0.370117  2.066500 -0.018599  ... -0.885845 -0.554700 -0.411581   \n",
       "2   -0.370117 -0.251070  0.672219  ... -0.885845 -0.554700 -0.411581   \n",
       "3   -0.370117  0.328322  0.326810  ...  1.128865 -0.554700  2.429655   \n",
       "4   -0.370117 -0.251070  0.672219  ... -0.885845 -0.554700 -0.411581   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "255       NaN       NaN  0.672219  ... -0.885845 -0.554700       NaN   \n",
       "256       NaN       NaN -1.745643  ... -0.885845 -0.554700       NaN   \n",
       "257       NaN       NaN -0.018599  ... -0.885845 -0.554700       NaN   \n",
       "258       NaN       NaN  0.326810  ...  1.128865  1.802776       NaN   \n",
       "259       NaN       NaN  0.672219  ...  1.128865  1.802776       NaN   \n",
       "\n",
       "           63        64        65        66        67        68        69  \n",
       "0    3.152380 -0.460721 -0.485363 -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "1    3.152380 -0.460721 -0.485363 -0.497468 -0.672593       NaN -0.509486  \n",
       "2         NaN -0.460721 -0.485363 -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "3   -0.317221 -0.460721 -0.485363 -0.497468 -0.672593       NaN  0.870373  \n",
       "4         NaN -0.460721 -0.485363 -0.497468 -0.672593       NaN -0.509486  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "255 -0.317221 -0.460721  2.060315 -0.497468  1.486784 -0.072169 -0.509486  \n",
       "256 -0.317221 -0.460721 -0.485363 -0.497468  1.486784 -0.072169  0.870373  \n",
       "257       NaN -0.460721  2.060315 -0.497468  1.486784 -0.072169  0.870373  \n",
       "258 -0.317221 -0.460721 -0.485363 -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "259 -0.317221 -0.460721 -0.485363 -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "\n",
       "[260 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_sc = df_tbi\n",
    "df_new_tbi_target = df_tbi['d_kl_tl']\n",
    "df_new_array = scaler.fit_transform(df_sc)\n",
    "df_tbi_f = pd.DataFrame(df_new_array)\n",
    "df_tbi_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1923e7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>age_at_record</th>\n",
       "      <th>sex</th>\n",
       "      <th>tbi_cli_reason</th>\n",
       "      <th>tbi_cli_time_acci_hos</th>\n",
       "      <th>tbi_cli_pulse</th>\n",
       "      <th>tbi_cli_temp</th>\n",
       "      <th>tbi_cli_blood_pressure</th>\n",
       "      <th>tbi_cli_breathing_rate</th>\n",
       "      <th>tbi_cli_glasgow</th>\n",
       "      <th>...</th>\n",
       "      <th>ast_v2</th>\n",
       "      <th>alt_v2</th>\n",
       "      <th>d_2_protein</th>\n",
       "      <th>albumin_v2</th>\n",
       "      <th>ure_v2</th>\n",
       "      <th>creatinin_v2</th>\n",
       "      <th>prothrombin_v2</th>\n",
       "      <th>d_3_aptt</th>\n",
       "      <th>d_4_dtim</th>\n",
       "      <th>d_kl_tl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.804484</td>\n",
       "      <td>0.402031</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.194118</td>\n",
       "      <td>-0.792786</td>\n",
       "      <td>-0.795610</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>3.152380</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.792256</td>\n",
       "      <td>1.489632</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>4.288194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.134370</td>\n",
       "      <td>0.442006</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>2.066500</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>3.152380</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.767799</td>\n",
       "      <td>-0.307274</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.074964</td>\n",
       "      <td>-0.383072</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>-0.251070</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.755571</td>\n",
       "      <td>1.064049</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.322489</td>\n",
       "      <td>-0.795610</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>0.328322</td>\n",
       "      <td>0.326810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>2.429655</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.743342</td>\n",
       "      <td>-1.111153</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.182502</td>\n",
       "      <td>0.618104</td>\n",
       "      <td>0.442006</td>\n",
       "      <td>-0.370117</td>\n",
       "      <td>-0.251070</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>-0.411581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.643916</td>\n",
       "      <td>-1.016579</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>4.288194</td>\n",
       "      <td>-0.194118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>2.060315</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>1.486784</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1.656145</td>\n",
       "      <td>-0.165413</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.194118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.745643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>1.486784</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>0.870373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.668373</td>\n",
       "      <td>1.915215</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>8.157150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.885845</td>\n",
       "      <td>-0.554700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>2.060315</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>1.486784</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>0.870373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.680602</td>\n",
       "      <td>0.023735</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.176695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326810</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1.692830</td>\n",
       "      <td>-0.023552</td>\n",
       "      <td>-0.578836</td>\n",
       "      <td>-0.421243</td>\n",
       "      <td>-0.188310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672219</td>\n",
       "      <td>...</td>\n",
       "      <td>1.128865</td>\n",
       "      <td>1.802776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.317221</td>\n",
       "      <td>-0.460721</td>\n",
       "      <td>-0.485363</td>\n",
       "      <td>-0.497468</td>\n",
       "      <td>-0.672593</td>\n",
       "      <td>-0.072169</td>\n",
       "      <td>-0.509486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     record_id  age_at_record       sex  tbi_cli_reason  \\\n",
       "0    -1.804484       0.402031 -0.578836       -0.421243   \n",
       "1    -1.792256       1.489632 -0.578836        4.288194   \n",
       "2    -1.767799      -0.307274 -0.578836       -0.421243   \n",
       "3    -1.755571       1.064049 -0.578836       -0.421243   \n",
       "4    -1.743342      -1.111153 -0.578836       -0.421243   \n",
       "..         ...            ...       ...             ...   \n",
       "255   1.643916      -1.016579 -0.578836        4.288194   \n",
       "256   1.656145      -0.165413 -0.578836       -0.421243   \n",
       "257   1.668373       1.915215 -0.578836       -0.421243   \n",
       "258   1.680602       0.023735 -0.578836       -0.421243   \n",
       "259   1.692830      -0.023552 -0.578836       -0.421243   \n",
       "\n",
       "     tbi_cli_time_acci_hos  tbi_cli_pulse  tbi_cli_temp  \\\n",
       "0                -0.194118      -0.792786     -0.795610   \n",
       "1                      NaN      -0.134370      0.442006   \n",
       "2                      NaN      -1.074964     -0.383072   \n",
       "3                      NaN      -0.322489     -0.795610   \n",
       "4                -0.182502       0.618104      0.442006   \n",
       "..                     ...            ...           ...   \n",
       "255              -0.194118            NaN           NaN   \n",
       "256              -0.194118            NaN           NaN   \n",
       "257               8.157150            NaN           NaN   \n",
       "258              -0.176695            NaN           NaN   \n",
       "259              -0.188310            NaN           NaN   \n",
       "\n",
       "     tbi_cli_blood_pressure  tbi_cli_breathing_rate  tbi_cli_glasgow  ...  \\\n",
       "0                 -0.370117                0.328322        -0.018599  ...   \n",
       "1                 -0.370117                2.066500        -0.018599  ...   \n",
       "2                 -0.370117               -0.251070         0.672219  ...   \n",
       "3                 -0.370117                0.328322         0.326810  ...   \n",
       "4                 -0.370117               -0.251070         0.672219  ...   \n",
       "..                      ...                     ...              ...  ...   \n",
       "255                     NaN                     NaN         0.672219  ...   \n",
       "256                     NaN                     NaN        -1.745643  ...   \n",
       "257                     NaN                     NaN        -0.018599  ...   \n",
       "258                     NaN                     NaN         0.326810  ...   \n",
       "259                     NaN                     NaN         0.672219  ...   \n",
       "\n",
       "       ast_v2    alt_v2  d_2_protein  albumin_v2    ure_v2  creatinin_v2  \\\n",
       "0    1.128865  1.802776    -0.411581    3.152380 -0.460721     -0.485363   \n",
       "1   -0.885845 -0.554700    -0.411581    3.152380 -0.460721     -0.485363   \n",
       "2   -0.885845 -0.554700    -0.411581         NaN -0.460721     -0.485363   \n",
       "3    1.128865 -0.554700     2.429655   -0.317221 -0.460721     -0.485363   \n",
       "4   -0.885845 -0.554700    -0.411581         NaN -0.460721     -0.485363   \n",
       "..        ...       ...          ...         ...       ...           ...   \n",
       "255 -0.885845 -0.554700          NaN   -0.317221 -0.460721      2.060315   \n",
       "256 -0.885845 -0.554700          NaN   -0.317221 -0.460721     -0.485363   \n",
       "257 -0.885845 -0.554700          NaN         NaN -0.460721      2.060315   \n",
       "258  1.128865  1.802776          NaN   -0.317221 -0.460721     -0.485363   \n",
       "259  1.128865  1.802776          NaN   -0.317221 -0.460721     -0.485363   \n",
       "\n",
       "     prothrombin_v2  d_3_aptt  d_4_dtim   d_kl_tl  \n",
       "0         -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "1         -0.497468 -0.672593       NaN -0.509486  \n",
       "2         -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "3         -0.497468 -0.672593       NaN  0.870373  \n",
       "4         -0.497468 -0.672593       NaN -0.509486  \n",
       "..              ...       ...       ...       ...  \n",
       "255       -0.497468  1.486784 -0.072169 -0.509486  \n",
       "256       -0.497468  1.486784 -0.072169  0.870373  \n",
       "257       -0.497468  1.486784 -0.072169  0.870373  \n",
       "258       -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "259       -0.497468 -0.672593 -0.072169 -0.509486  \n",
       "\n",
       "[260 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tbi_f.columns = df_tbi.columns.to_list()\n",
    "df_tbi_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41fdaf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Data columns (total 70 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   record_id                                     260 non-null    float64\n",
      " 1   age_at_record                                 260 non-null    float64\n",
      " 2   sex                                           260 non-null    float64\n",
      " 3   tbi_cli_reason                                260 non-null    float64\n",
      " 4   tbi_cli_time_acci_hos                         260 non-null    float64\n",
      " 5   tbi_cli_pulse                                 260 non-null    float64\n",
      " 6   tbi_cli_temp                                  260 non-null    float64\n",
      " 7   tbi_cli_blood_pressure                        260 non-null    float64\n",
      " 8   tbi_cli_breathing_rate                        260 non-null    float64\n",
      " 9   tbi_cli_glasgow                               260 non-null    float64\n",
      " 10  tbi_cli_awaken                                260 non-null    float64\n",
      " 11  tbi_cli_headache                              260 non-null    float64\n",
      " 12  tbi_cli_blue                                  260 non-null    float64\n",
      " 13  tbi_cli_para_ner                              260 non-null    float64\n",
      " 14  tbi_cli_quadriplegia                          260 non-null    float64\n",
      " 15  tbi_cli_epileptic                             260 non-null    float64\n",
      " 16  tbi_cli_stiff_neck                            260 non-null    float64\n",
      " 17  tbi_cli_dam_chest_abdomen                     260 non-null    float64\n",
      " 18  tbi_cli_recall                                260 non-null    float64\n",
      " 19  tbi_cli_pupils_left_size                      260 non-null    float64\n",
      " 20  tbi_cli_pupils_left_reflex                    260 non-null    float64\n",
      " 21  tbi_cli_pupils_right_size                     260 non-null    float64\n",
      " 22  tbi_cli_pupils_right_reflex                   260 non-null    float64\n",
      " 23  tbi_cli_diabetes                              260 non-null    float64\n",
      " 24  tbi_cli_hypertension                          260 non-null    float64\n",
      " 25  tbi_cli_stroke                                260 non-null    float64\n",
      " 26  tbi_cli_cardiovascular                        260 non-null    float64\n",
      " 27  tbi_ct_brain_parenchyma___1                   260 non-null    float64\n",
      " 28  tbi_ct_brain_parenchyma___2                   260 non-null    float64\n",
      " 29  tbi_ct_brain_parenchyma___3                   260 non-null    float64\n",
      " 30  tbi_ct_brain_parenchyma___4                   260 non-null    float64\n",
      " 31  tbi_ct_brain_parenchyma___5                   260 non-null    float64\n",
      " 32  tbi_ct_brain_parenchyma___6                   260 non-null    float64\n",
      " 33  tbi_ct_brain_parenchyma___7                   260 non-null    float64\n",
      " 34  tbi_ct_brain_parenchyma___8                   260 non-null    float64\n",
      " 35  tbi_ct_brain_parenchyma___9                   260 non-null    float64\n",
      " 36  tbi_ct_brain_parenchyma___10                  260 non-null    float64\n",
      " 37  tbi_ct_brain_parenchyma___11                  260 non-null    float64\n",
      " 38  tbi_ct_brain_parenchyma___12                  260 non-null    float64\n",
      " 39  tbi_ct_epidural_hematoma_volume               260 non-null    float64\n",
      " 40  tbi_ct_epidural_hematoma_proportion           260 non-null    float64\n",
      " 41  tbi_ct_epidural_hematoma_value                260 non-null    float64\n",
      " 42  tbi_ct_subdural_hematoma_thick                260 non-null    float64\n",
      " 43  tbi_ct_subdural_hematoma_position_proprotion  260 non-null    float64\n",
      " 44  tbi_ct_subdural_hematoma_position_value       260 non-null    float64\n",
      " 45  tbi_ct_cerebral_contusion_volume              260 non-null    float64\n",
      " 46  tbi_ct_blood_hematoma_volume                  260 non-null    float64\n",
      " 47  tbi_ct_blood_hematoma_proportion              260 non-null    float64\n",
      " 48  tbi_ct_blood_hematoma_value                   260 non-null    float64\n",
      " 49  tbi_ct_subarachnoid_characteristic            260 non-null    float64\n",
      " 50  tbi_ct_midline_shift_width                    260 non-null    float64\n",
      " 51  tbi_ct_bottom_tank_characteristic             260 non-null    float64\n",
      " 52  tbi_ct_skull_fracture_characteristic          260 non-null    float64\n",
      " 53  tbi_ct_skull_risk                             260 non-null    float64\n",
      " 54  tbi_ct_rotterdam                              260 non-null    float64\n",
      " 55  hong_cau_v2                                   260 non-null    float64\n",
      " 56  bach_cau_v2                                   260 non-null    float64\n",
      " 57  tieu_cau_v2                                   260 non-null    float64\n",
      " 58  d_1_hst                                       260 non-null    float64\n",
      " 59  ethanol                                       260 non-null    float64\n",
      " 60  ast_v2                                        260 non-null    float64\n",
      " 61  alt_v2                                        260 non-null    float64\n",
      " 62  d_2_protein                                   260 non-null    float64\n",
      " 63  albumin_v2                                    260 non-null    float64\n",
      " 64  ure_v2                                        260 non-null    float64\n",
      " 65  creatinin_v2                                  260 non-null    float64\n",
      " 66  prothrombin_v2                                260 non-null    float64\n",
      " 67  d_3_aptt                                      260 non-null    float64\n",
      " 68  d_4_dtim                                      260 non-null    float64\n",
      " 69  d_kl_tl                                       260 non-null    float64\n",
      "dtypes: float64(70)\n",
      "memory usage: 142.3 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_tbi_k = pd.DataFrame(knn_imputer.fit_transform(df_tbi_f), columns=df_tbi_f.columns)\n",
    "df_tbi_k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb337c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Data columns (total 68 columns):\n",
      " #   Column                                        Non-Null Count  Dtype  \n",
      "---  ------                                        --------------  -----  \n",
      " 0   age_at_record                                 260 non-null    float64\n",
      " 1   sex                                           260 non-null    float64\n",
      " 2   tbi_cli_reason                                260 non-null    float64\n",
      " 3   tbi_cli_time_acci_hos                         260 non-null    float64\n",
      " 4   tbi_cli_pulse                                 260 non-null    float64\n",
      " 5   tbi_cli_temp                                  260 non-null    float64\n",
      " 6   tbi_cli_blood_pressure                        260 non-null    float64\n",
      " 7   tbi_cli_breathing_rate                        260 non-null    float64\n",
      " 8   tbi_cli_glasgow                               260 non-null    float64\n",
      " 9   tbi_cli_awaken                                260 non-null    float64\n",
      " 10  tbi_cli_headache                              260 non-null    float64\n",
      " 11  tbi_cli_blue                                  260 non-null    float64\n",
      " 12  tbi_cli_para_ner                              260 non-null    float64\n",
      " 13  tbi_cli_quadriplegia                          260 non-null    float64\n",
      " 14  tbi_cli_epileptic                             260 non-null    float64\n",
      " 15  tbi_cli_stiff_neck                            260 non-null    float64\n",
      " 16  tbi_cli_dam_chest_abdomen                     260 non-null    float64\n",
      " 17  tbi_cli_recall                                260 non-null    float64\n",
      " 18  tbi_cli_pupils_left_size                      260 non-null    float64\n",
      " 19  tbi_cli_pupils_left_reflex                    260 non-null    float64\n",
      " 20  tbi_cli_pupils_right_size                     260 non-null    float64\n",
      " 21  tbi_cli_pupils_right_reflex                   260 non-null    float64\n",
      " 22  tbi_cli_diabetes                              260 non-null    float64\n",
      " 23  tbi_cli_hypertension                          260 non-null    float64\n",
      " 24  tbi_cli_stroke                                260 non-null    float64\n",
      " 25  tbi_cli_cardiovascular                        260 non-null    float64\n",
      " 26  tbi_ct_brain_parenchyma___1                   260 non-null    float64\n",
      " 27  tbi_ct_brain_parenchyma___2                   260 non-null    float64\n",
      " 28  tbi_ct_brain_parenchyma___3                   260 non-null    float64\n",
      " 29  tbi_ct_brain_parenchyma___4                   260 non-null    float64\n",
      " 30  tbi_ct_brain_parenchyma___5                   260 non-null    float64\n",
      " 31  tbi_ct_brain_parenchyma___6                   260 non-null    float64\n",
      " 32  tbi_ct_brain_parenchyma___7                   260 non-null    float64\n",
      " 33  tbi_ct_brain_parenchyma___8                   260 non-null    float64\n",
      " 34  tbi_ct_brain_parenchyma___9                   260 non-null    float64\n",
      " 35  tbi_ct_brain_parenchyma___10                  260 non-null    float64\n",
      " 36  tbi_ct_brain_parenchyma___11                  260 non-null    float64\n",
      " 37  tbi_ct_brain_parenchyma___12                  260 non-null    float64\n",
      " 38  tbi_ct_epidural_hematoma_volume               260 non-null    float64\n",
      " 39  tbi_ct_epidural_hematoma_proportion           260 non-null    float64\n",
      " 40  tbi_ct_epidural_hematoma_value                260 non-null    float64\n",
      " 41  tbi_ct_subdural_hematoma_thick                260 non-null    float64\n",
      " 42  tbi_ct_subdural_hematoma_position_proprotion  260 non-null    float64\n",
      " 43  tbi_ct_subdural_hematoma_position_value       260 non-null    float64\n",
      " 44  tbi_ct_cerebral_contusion_volume              260 non-null    float64\n",
      " 45  tbi_ct_blood_hematoma_volume                  260 non-null    float64\n",
      " 46  tbi_ct_blood_hematoma_proportion              260 non-null    float64\n",
      " 47  tbi_ct_blood_hematoma_value                   260 non-null    float64\n",
      " 48  tbi_ct_subarachnoid_characteristic            260 non-null    float64\n",
      " 49  tbi_ct_midline_shift_width                    260 non-null    float64\n",
      " 50  tbi_ct_bottom_tank_characteristic             260 non-null    float64\n",
      " 51  tbi_ct_skull_fracture_characteristic          260 non-null    float64\n",
      " 52  tbi_ct_skull_risk                             260 non-null    float64\n",
      " 53  tbi_ct_rotterdam                              260 non-null    float64\n",
      " 54  hong_cau_v2                                   260 non-null    float64\n",
      " 55  bach_cau_v2                                   260 non-null    float64\n",
      " 56  tieu_cau_v2                                   260 non-null    float64\n",
      " 57  d_1_hst                                       260 non-null    float64\n",
      " 58  ethanol                                       260 non-null    float64\n",
      " 59  ast_v2                                        260 non-null    float64\n",
      " 60  alt_v2                                        260 non-null    float64\n",
      " 61  d_2_protein                                   260 non-null    float64\n",
      " 62  albumin_v2                                    260 non-null    float64\n",
      " 63  ure_v2                                        260 non-null    float64\n",
      " 64  creatinin_v2                                  260 non-null    float64\n",
      " 65  prothrombin_v2                                260 non-null    float64\n",
      " 66  d_3_aptt                                      260 non-null    float64\n",
      " 67  d_4_dtim                                      260 non-null    float64\n",
      "dtypes: float64(68)\n",
      "memory usage: 138.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_tbi_l = df_tbi_k.drop(\"d_kl_tl\", axis = 1)\n",
    "df_tbi_i = df_tbi_l.drop(\"record_id\", axis = 1)\n",
    "df_tbi_i.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "343669b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 260 entries, 0 to 259\n",
      "Series name: d_kl_tl\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "260 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 2.2 KB\n"
     ]
    }
   ],
   "source": [
    "X= df_tbi_i\n",
    "y = df_new_tbi_target\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ce87e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    142\n",
      "3     80\n",
      "1     20\n",
      "4     18\n",
      "Name: d_kl_tl, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cc3e949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7423076923076922\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "# loo = LeaveOneOut()\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store true and predicted labels\n",
    "# List to store accuracies\n",
    "accuracies = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Apply SMOTE to balance the training data\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "   # Train the Random Forest model\n",
    "    rf_model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    # Compute accuracy and append to the list\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Compute the mean accuracy\n",
    "mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9bb50b",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e064347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "svm_model = make_pipeline(SVC())\n",
    "logreg_model = make_pipeline(LogisticRegression())\n",
    "dt_model = make_pipeline(DecisionTreeClassifier())\n",
    "knn_model = make_pipeline(KNeighborsClassifier(n_neighbors=5))\n",
    "gnb = make_pipeline(GaussianNB())\n",
    "rf = make_pipeline(RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "# Create a list of models\n",
    "models = [logreg_model,svm_model,  dt_model, knn_model, gnb,rf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aefee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X before SMOTE: (260, 68)\n",
      "Shape of X after SMOTE: (568, 68)\n"
     ]
    }
   ],
   "source": [
    "#### SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Apply SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state= None)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "print(f'''Shape of X before SMOTE: {X.shape}\n",
    "Shape of X after SMOTE: {X_resampled.shape}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8bcc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Assuming X is your data and y is the corresponding labels\n",
    "# Replace X and y with your actual data and labels\n",
    "# model initialization\n",
    "model = TSNE(n_components=2, perplexity=15, random_state=0)\n",
    "\n",
    "# Fit t-SNE model to your data\n",
    "tsne_data = model.fit_transform(X_resampled)\n",
    "\n",
    "# Stack the t-SNE transformed data with labels\n",
    "tsne_data = np.vstack((tsne_data.T, y_resampled)).T\n",
    "\n",
    "# Create a DataFrame for the t-SNE transformed data\n",
    "tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
    "\n",
    "# Plot the t-SNE transformed data using seaborn scatterplot\n",
    "sns.scatterplot(data=tsne_df, x='Dim_1', y='Dim_2', hue='label', palette=\"bright\")\n",
    "# plt.title('t-SNE Visualization of 4 Classes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3342436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    142\n",
      "3     80\n",
      "1     20\n",
      "4     18\n",
      "Name: d_kl_tl, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d32cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of folds (k = 10)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# Initialize Leave-One-Out Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Create GridSearchCV object with LOOCV\n",
    "grid_search_rf = GridSearchCV(random_forest, param_grid_rf, cv=loo, scoring='accuracy')\n",
    "\n",
    "# Lists to store predictions and true labels\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in loo.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    smote = SMOTE(random_state=None)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Fit the model\n",
    "    grid_search_rf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = grid_search_rf.predict(X_test)\n",
    "    \n",
    "    # Append predictions and true labels\n",
    "    predictions.append(y_pred[0])\n",
    "    true_labels.append(y_test[0])\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Best Parameters\n",
    "print(\"Best Parameters: \", grid_search_rf.best_params_)\n",
    "\n",
    "# Best Accuracy\n",
    "print(\"Best Accuracy: \", grid_search_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194f9a2",
   "metadata": {},
   "source": [
    "#### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in loo.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9bdaa",
   "metadata": {},
   "source": [
    "#### k fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "\n",
    "# Use KFold cross-validation for evaluation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over models\n",
    "for model, param_grid in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='accuracy')\n",
    "    \n",
    "    accuracy_scores_model = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Apply SMOTE for balancing the classes\n",
    "        smote = SMOTE(random_state=None)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        # Train model on resampled training data\n",
    "        grid_search.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy and append to list\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracy_scores_model.append(accuracy)\n",
    "    \n",
    "    # Calculate mean accuracy for this model\n",
    "    mean_accuracy = np.mean(accuracy_scores_model)\n",
    "    \n",
    "    # Append mean accuracy to list\n",
    "    accuracy_scores.append(mean_accuracy)\n",
    "\n",
    "# Print results\n",
    "for i, (model, _) in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773da26",
   "metadata": {},
   "source": [
    "#### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d79fb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models with their hyperparameter grids\n",
    "svm_model = make_pipeline(SVC())\n",
    "svm_param_grid = {'svc__kernel': ['linear', 'rbf']}\n",
    "\n",
    "logreg_model = make_pipeline(LogisticRegression(max_iter=1000))\n",
    "logreg_param_grid = {'logisticregression__C': [0.1, 1, 10]}\n",
    "\n",
    "\n",
    "dt_model = make_pipeline(DecisionTreeClassifier())\n",
    "dt_param_grid = {'decisiontreeclassifier__max_depth': [None, 10, 20], 'decisiontreeclassifier__min_samples_split': [2, 5, 10]}\n",
    "\n",
    "knn_model = make_pipeline(KNeighborsClassifier())\n",
    "knn_param_grid = {'kneighborsclassifier__n_neighbors': [3, 5, 7,9]}\n",
    "\n",
    "gnb_model = make_pipeline( GaussianNB())\n",
    "\n",
    "\n",
    "# Define Random Forest model and its hyperparameter grid\n",
    "rf_model = make_pipeline(RandomForestClassifier())\n",
    "rf_param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200],\n",
    "    'randomforestclassifier__max_depth': [10],\n",
    "    'randomforestclassifier__min_samples_split': [2],\n",
    "    'randomforestclassifier__min_samples_leaf': [1]\n",
    "}\n",
    "\n",
    "# Create a list of models with their corresponding parameter grids\n",
    "models = [\n",
    "    (logreg_model, logreg_param_grid),\n",
    "    (svm_model, svm_param_grid),\n",
    "    (dt_model, dt_param_grid),\n",
    "    (knn_model, knn_param_grid),\n",
    "    (gnb_model, {}),\n",
    "    (rf_model, rf_param_grid),  # Add Random Forest model and its hyperparameter grid\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3685cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "# Iterate over models\n",
    "for model, param_grid in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    accuracy_scores_model = []\n",
    "    for train_index, test_index in k_fold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        \n",
    "        # Train model on training data\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Calculate accuracy and append to list\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracy_scores_model.append(accuracy)\n",
    "    \n",
    "    # Calculate mean accuracy for this model\n",
    "    mean_accuracy = np.mean(accuracy_scores_model)\n",
    "    \n",
    "    # Append mean accuracy to list\n",
    "    accuracy_scores.append(mean_accuracy)\n",
    "\n",
    "# Print results\n",
    "for i, (model, _) in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ea183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "# Iterate over models\n",
    "for model, param_grid in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=k_fold, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in k_fold.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index],y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(best_model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, (model, _) in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e72ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
