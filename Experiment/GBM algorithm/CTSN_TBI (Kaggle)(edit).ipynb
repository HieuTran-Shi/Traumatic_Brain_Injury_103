{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079e5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, Normalizer\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneOut, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e12cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\CTSN_TBI\\Machine_learning\\GBM algorithm\n",
      "F:\\CTSN_TBI\\Machine_learning\\GBM algorithm\\Kaggle\\Dataset_TBI.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Data\n",
    "print(os.getcwd())\n",
    "\n",
    "data_dir = os.getcwd() + \"\\\\Kaggle\\\\Dataset_TBI.xlsx\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b289d521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marshall (t0)</th>\n",
       "      <th>Entry Diagnosis (t0)</th>\n",
       "      <th>CRS-R (t1)</th>\n",
       "      <th>RLAS (t1)</th>\n",
       "      <th>DRS (t1)</th>\n",
       "      <th>ERBI A (t1)</th>\n",
       "      <th>ERBI B (t1)</th>\n",
       "      <th>GOS-E (t1)</th>\n",
       "      <th>Diagnosis at Discharge (t2)</th>\n",
       "      <th>CRS-R (t2)</th>\n",
       "      <th>RLAS (t2)</th>\n",
       "      <th>DRS (t2)</th>\n",
       "      <th>ERBI A (t2)</th>\n",
       "      <th>ERBI B (t2)</th>\n",
       "      <th>GOS-E (t2)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>76</td>\n",
       "      <td>M</td>\n",
       "      <td>V</td>\n",
       "      <td>MCS</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-175</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DEATH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>28</td>\n",
       "      <td>M</td>\n",
       "      <td>III</td>\n",
       "      <td>MCS</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>-125</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>EMERSION</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>II</td>\n",
       "      <td>MCS</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-175</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>EMERSION</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>II</td>\n",
       "      <td>EMERSION</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>-175</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>EMERSION</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S5</th>\n",
       "      <td>62</td>\n",
       "      <td>M</td>\n",
       "      <td>II</td>\n",
       "      <td>EMERSION</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>-100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>EMERSION</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Age Sex Marshall (t0) Entry Diagnosis (t0)  CRS-R (t1)  RLAS (t1)  \\\n",
       "Subject                                                                      \n",
       "S1        76   M             V                  MCS        10.0          3   \n",
       "S2        28   M           III                  MCS         8.0          3   \n",
       "S3        20   F            II                  MCS         9.0          3   \n",
       "S4        22   M            II             EMERSION        23.0          4   \n",
       "S5        62   M            II             EMERSION        23.0          4   \n",
       "\n",
       "         DRS (t1)  ERBI A (t1)  ERBI B (t1)  GOS-E (t1)  \\\n",
       "Subject                                                   \n",
       "S1             18         -175            0           3   \n",
       "S2             20         -125            0           2   \n",
       "S3             18         -175            0           2   \n",
       "S4             15         -175            0           3   \n",
       "S5             15         -100            5           3   \n",
       "\n",
       "        Diagnosis at Discharge (t2)  CRS-R (t2)  RLAS (t2)  DRS (t2)  \\\n",
       "Subject                                                                \n",
       "S1                            DEATH         NaN        NaN      30.0   \n",
       "S2                         EMERSION        23.0        7.0       8.0   \n",
       "S3                         EMERSION        23.0        7.0       6.0   \n",
       "S4                         EMERSION        23.0        7.0       3.0   \n",
       "S5                         EMERSION        23.0        6.0      10.0   \n",
       "\n",
       "         ERBI A (t2)  ERBI B (t2)  GOS-E (t2)  \n",
       "Subject                                        \n",
       "S1               NaN          NaN           1  \n",
       "S2               0.0         60.0           4  \n",
       "S3               0.0         70.0           4  \n",
       "S4               0.0        100.0           7  \n",
       "S5             -50.0         90.0           3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tbi = pd.read_excel(data_dir,index_col=0)\n",
    "df_tbi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc469227",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6b4d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102 entries, 0 to 101\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Subject                      102 non-null    object \n",
      " 1   Age                          102 non-null    int64  \n",
      " 2   Sex                          102 non-null    object \n",
      " 3   Marshall (t0)                99 non-null     object \n",
      " 4   Entry Diagnosis (t0)         102 non-null    object \n",
      " 5   CRS-R (t1)                   101 non-null    float64\n",
      " 6   RLAS (t1)                    102 non-null    int64  \n",
      " 7   DRS (t1)                     102 non-null    int64  \n",
      " 8   ERBI A (t1)                  102 non-null    int64  \n",
      " 9   ERBI B (t1)                  102 non-null    int64  \n",
      " 10  GOS-E (t1)                   102 non-null    int64  \n",
      " 11  Diagnosis at Discharge (t2)  102 non-null    object \n",
      " 12  CRS-R (t2)                   90 non-null     float64\n",
      " 13  RLAS (t2)                    90 non-null     float64\n",
      " 14  DRS (t2)                     100 non-null    float64\n",
      " 15  ERBI A (t2)                  90 non-null     float64\n",
      " 16  ERBI B (t2)                  90 non-null     float64\n",
      " 17  GOS-E (t2)                   102 non-null    int64  \n",
      "dtypes: float64(6), int64(7), object(5)\n",
      "memory usage: 14.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Subject', 'Age', 'Sex', 'Marshall (t0)', 'Entry Diagnosis (t0)',\n",
       "       'CRS-R (t1)', 'RLAS (t1)', 'DRS (t1)', 'ERBI A (t1)', 'ERBI B (t1)',\n",
       "       'GOS-E (t1)', 'Diagnosis at Discharge (t2)', 'CRS-R (t2)', 'RLAS (t2)',\n",
       "       'DRS (t2)', 'ERBI A (t2)', 'ERBI B (t2)', 'GOS-E (t2)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tbi = pd.read_excel(data_dir)\n",
    "df_tbi1 = df_tbi.drop(\"Subject\", axis = 1)\n",
    "df_tbi.info()\n",
    "df_tbi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c392e555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Marshall (t0)</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRS-R (t1)</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRS-R (t2)</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RLAS (t2)</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRS (t2)</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERBI A (t2)</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERBI B (t2)</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "Marshall (t0)   3\n",
       "CRS-R (t1)      1\n",
       "CRS-R (t2)     12\n",
       "RLAS (t2)      12\n",
       "DRS (t2)        2\n",
       "ERBI A (t2)    12\n",
       "ERBI B (t2)    12"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df = pd.DataFrame(df_tbi.isnull().sum())\n",
    "null_df[null_df[0]>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83738ae6",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c58513",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f545b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tbi4 = df_tbi.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8150235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4ef1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'II': '2',\n",
    "    'III': '3',\n",
    "    'IV': '4',\n",
    "    'V': '5',\n",
    "    'VI': '6'}\n",
    "df_tbi4['Marshall (t0)'] = df_tbi4['Marshall (t0)'].replace(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a329f7",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a6dc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANGO\\AppData\\Local\\Temp\\ipykernel_18496\\3641519914.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_tbi4x= df_tbi4.drop('Subject', 1, errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marshall (t0)</th>\n",
       "      <th>Entry Diagnosis (t0)</th>\n",
       "      <th>CRS-R (t1)</th>\n",
       "      <th>RLAS (t1)</th>\n",
       "      <th>DRS (t1)</th>\n",
       "      <th>ERBI A (t1)</th>\n",
       "      <th>ERBI B (t1)</th>\n",
       "      <th>GOS-E (t1)</th>\n",
       "      <th>Diagnosis at Discharge (t2)</th>\n",
       "      <th>CRS-R (t2)</th>\n",
       "      <th>RLAS (t2)</th>\n",
       "      <th>DRS (t2)</th>\n",
       "      <th>ERBI A (t2)</th>\n",
       "      <th>ERBI B (t2)</th>\n",
       "      <th>GOS-E (t2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-175</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>-125</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>-175</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>-175</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>-100</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex Marshall (t0)  Entry Diagnosis (t0)  CRS-R (t1)  RLAS (t1)  \\\n",
       "0   76    1             5                     2        10.0          3   \n",
       "1   28    1             3                     2         8.0          3   \n",
       "2   20    0             2                     2         9.0          3   \n",
       "3   22    1             2                     0        23.0          4   \n",
       "4   62    1             2                     0        23.0          4   \n",
       "\n",
       "   DRS (t1)  ERBI A (t1)  ERBI B (t1)  GOS-E (t1)  \\\n",
       "0        18         -175            0           3   \n",
       "1        20         -125            0           2   \n",
       "2        18         -175            0           2   \n",
       "3        15         -175            0           3   \n",
       "4        15         -100            5           3   \n",
       "\n",
       "   Diagnosis at Discharge (t2)  CRS-R (t2)  RLAS (t2)  DRS (t2)  ERBI A (t2)  \\\n",
       "0                            0         NaN        NaN      30.0          NaN   \n",
       "1                            1        23.0        7.0       8.0          0.0   \n",
       "2                            1        23.0        7.0       6.0          0.0   \n",
       "3                            1        23.0        7.0       3.0          0.0   \n",
       "4                            1        23.0        6.0      10.0        -50.0   \n",
       "\n",
       "   ERBI B (t2)  GOS-E (t2)  \n",
       "0          NaN           1  \n",
       "1         60.0           4  \n",
       "2         70.0           4  \n",
       "3        100.0           7  \n",
       "4         90.0           3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "\n",
    "# Encode labels in column 'species'. \n",
    "df_tbi4['Sex']= label_encoder.fit_transform(df_tbi4['Sex']) \n",
    "df_tbi4['Entry Diagnosis (t0)']= label_encoder.fit_transform(df_tbi4['Entry Diagnosis (t0)'])\n",
    "df_tbi4['Diagnosis at Discharge (t2)']= label_encoder.fit_transform(df_tbi4['Diagnosis at Discharge (t2)'])\n",
    "df_tbi4x= df_tbi4.drop('Subject', 1, errors='ignore')\n",
    "\n",
    "df_tbi4x.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf41d7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marshall (t0)</th>\n",
       "      <th>Entry Diagnosis (t0)</th>\n",
       "      <th>CRS-R (t1)</th>\n",
       "      <th>RLAS (t1)</th>\n",
       "      <th>DRS (t1)</th>\n",
       "      <th>ERBI A (t1)</th>\n",
       "      <th>ERBI B (t1)</th>\n",
       "      <th>GOS-E (t1)</th>\n",
       "      <th>Diagnosis at Discharge (t2)</th>\n",
       "      <th>CRS-R (t2)</th>\n",
       "      <th>RLAS (t2)</th>\n",
       "      <th>DRS (t2)</th>\n",
       "      <th>ERBI A (t2)</th>\n",
       "      <th>ERBI B (t2)</th>\n",
       "      <th>GOS-E (t2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.380828</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>1.087012</td>\n",
       "      <td>0.673219</td>\n",
       "      <td>-0.818321</td>\n",
       "      <td>-0.585028</td>\n",
       "      <td>-0.156150</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-1.149958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.075281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.389551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.960077</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-0.377127</td>\n",
       "      <td>0.673219</td>\n",
       "      <td>-1.074205</td>\n",
       "      <td>-0.585028</td>\n",
       "      <td>0.305510</td>\n",
       "      <td>0.381824</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>-1.171364</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>-0.498348</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>-0.043973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.350228</td>\n",
       "      <td>-1.586582</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>0.673219</td>\n",
       "      <td>-0.946263</td>\n",
       "      <td>-0.585028</td>\n",
       "      <td>-0.156150</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>-1.171364</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>-0.732315</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.368701</td>\n",
       "      <td>-0.043973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.252690</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>0.043107</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>-1.083264</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>1.155651</td>\n",
       "      <td>1.301605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.698064</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>0.043107</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>0.720485</td>\n",
       "      <td>1.030489</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.080257</td>\n",
       "      <td>-0.264382</td>\n",
       "      <td>-0.452267</td>\n",
       "      <td>0.893335</td>\n",
       "      <td>-0.492499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-1.398997</td>\n",
       "      <td>-1.586582</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>1.927514</td>\n",
       "      <td>-1.310300</td>\n",
       "      <td>1.397807</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>1.284116</td>\n",
       "      <td>-1.434213</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>1.155651</td>\n",
       "      <td>1.750131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.868516</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>1.087012</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>0.671243</td>\n",
       "      <td>-0.156150</td>\n",
       "      <td>0.720485</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>-0.521672</td>\n",
       "      <td>0.671483</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>-1.467517</td>\n",
       "      <td>-0.492499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.380828</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>1.299378</td>\n",
       "      <td>-0.156150</td>\n",
       "      <td>2.075130</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>0.203551</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>-0.680566</td>\n",
       "      <td>-0.492499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-1.252690</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>1.087012</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>1.927514</td>\n",
       "      <td>-2.464451</td>\n",
       "      <td>2.075130</td>\n",
       "      <td>2.312317</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>-0.615331</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>-1.336358</td>\n",
       "      <td>-0.492499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.454220</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>1.927514</td>\n",
       "      <td>-1.079470</td>\n",
       "      <td>1.397807</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>0.627250</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>1.284116</td>\n",
       "      <td>-0.030416</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.368701</td>\n",
       "      <td>-0.043973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age       Sex  Marshall (t0)  Entry Diagnosis (t0)  CRS-R (t1)  \\\n",
       "0    1.380828  0.630286       1.087012              0.673219   -0.818321   \n",
       "1   -0.960077  0.630286      -0.377127              0.673219   -1.074205   \n",
       "2   -1.350228 -1.586582      -1.109196              0.673219   -0.946263   \n",
       "3   -1.252690  0.630286      -1.109196             -0.869890    0.844923   \n",
       "4    0.698064  0.630286      -1.109196             -0.869890    0.844923   \n",
       "..        ...       ...            ...                   ...         ...   \n",
       "97  -1.398997 -1.586582      -1.109196             -0.869890    0.844923   \n",
       "98   1.868516  0.630286       1.087012             -0.869890    0.844923   \n",
       "99   1.380828  0.630286      -1.109196             -0.869890    0.844923   \n",
       "100 -1.252690  0.630286       1.087012             -0.869890    0.844923   \n",
       "101  0.454220  0.630286      -1.109196             -0.869890    0.844923   \n",
       "\n",
       "     RLAS (t1)  DRS (t1)  ERBI A (t1)  ERBI B (t1)  GOS-E (t1)  \\\n",
       "0    -0.585028 -0.156150    -0.295498    -0.251339    0.853706   \n",
       "1    -0.585028  0.305510     0.381824    -0.251339   -1.171364   \n",
       "2    -0.585028 -0.156150    -0.295498    -0.251339   -1.171364   \n",
       "3     0.043107 -0.848640    -0.295498    -0.251339    0.853706   \n",
       "4     0.043107 -0.848640     0.720485     1.030489    0.853706   \n",
       "..         ...       ...          ...          ...         ...   \n",
       "97    1.927514 -1.310300     1.397807    -0.251339    0.853706   \n",
       "98    0.671243 -0.156150     0.720485    -0.251339    0.853706   \n",
       "99    1.299378 -0.156150     2.075130    -0.251339    0.853706   \n",
       "100   1.927514 -2.464451     2.075130     2.312317    0.853706   \n",
       "101   1.927514 -1.079470     1.397807    -0.251339    0.853706   \n",
       "\n",
       "     Diagnosis at Discharge (t2)  CRS-R (t2)  RLAS (t2)  DRS (t2)  \\\n",
       "0                      -1.149958         NaN        NaN  2.075281   \n",
       "1                      -0.261354    0.427507   0.682187 -0.498348   \n",
       "2                      -0.261354    0.427507   0.682187 -0.732315   \n",
       "3                      -0.261354    0.427507   0.682187 -1.083264   \n",
       "4                      -0.261354    0.427507   0.080257 -0.264382   \n",
       "..                           ...         ...        ...       ...   \n",
       "97                     -0.261354    0.427507   1.284116 -1.434213   \n",
       "98                     -0.261354    0.427507  -0.521672  0.671483   \n",
       "99                     -0.261354    0.427507   0.682187  0.203551   \n",
       "100                    -0.261354    0.427507   0.682187 -0.615331   \n",
       "101                     0.627250    0.427507   1.284116 -0.030416   \n",
       "\n",
       "     ERBI A (t2)  ERBI B (t2)  GOS-E (t2)  \n",
       "0            NaN          NaN   -1.389551  \n",
       "1       0.452267     0.106384   -0.043973  \n",
       "2       0.452267     0.368701   -0.043973  \n",
       "3       0.452267     1.155651    1.301605  \n",
       "4      -0.452267     0.893335   -0.492499  \n",
       "..           ...          ...         ...  \n",
       "97      0.452267     1.155651    1.750131  \n",
       "98      0.452267    -1.467517   -0.492499  \n",
       "99      0.452267    -0.680566   -0.492499  \n",
       "100     0.452267    -1.336358   -0.492499  \n",
       "101     0.452267     0.368701   -0.043973  \n",
       "\n",
       "[102 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df_new_tbi_target = df_tbi['GOS-E (t2)']\n",
    "df_new_array = scaler.fit_transform(df_tbi4x)\n",
    "df_tbi_f = pd.DataFrame(df_new_array)\n",
    "df_tbi_f.columns = df_tbi4x.columns.to_list()\n",
    "df_tbi_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "094c22e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102 entries, 0 to 101\n",
      "Data columns (total 17 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Age                          102 non-null    float64\n",
      " 1   Sex                          102 non-null    float64\n",
      " 2   Marshall (t0)                102 non-null    float64\n",
      " 3   Entry Diagnosis (t0)         102 non-null    float64\n",
      " 4   CRS-R (t1)                   102 non-null    float64\n",
      " 5   RLAS (t1)                    102 non-null    float64\n",
      " 6   DRS (t1)                     102 non-null    float64\n",
      " 7   ERBI A (t1)                  102 non-null    float64\n",
      " 8   ERBI B (t1)                  102 non-null    float64\n",
      " 9   GOS-E (t1)                   102 non-null    float64\n",
      " 10  Diagnosis at Discharge (t2)  102 non-null    float64\n",
      " 11  CRS-R (t2)                   102 non-null    float64\n",
      " 12  RLAS (t2)                    102 non-null    float64\n",
      " 13  DRS (t2)                     102 non-null    float64\n",
      " 14  ERBI A (t2)                  102 non-null    float64\n",
      " 15  ERBI B (t2)                  102 non-null    float64\n",
      " 16  GOS-E (t2)                   102 non-null    float64\n",
      "dtypes: float64(17)\n",
      "memory usage: 13.7 KB\n"
     ]
    }
   ],
   "source": [
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "df_tbi5 = pd.DataFrame(knn_imputer.fit_transform(df_tbi_f), columns=df_tbi_f.columns)\n",
    "df_tbi5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1923e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HANGO\\AppData\\Local\\Temp\\ipykernel_18496\\3779281919.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_tbi5x= df_tbi5.drop('GOS-E (t2)', 1, errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Marshall (t0)</th>\n",
       "      <th>Entry Diagnosis (t0)</th>\n",
       "      <th>CRS-R (t1)</th>\n",
       "      <th>RLAS (t1)</th>\n",
       "      <th>DRS (t1)</th>\n",
       "      <th>ERBI A (t1)</th>\n",
       "      <th>ERBI B (t1)</th>\n",
       "      <th>GOS-E (t1)</th>\n",
       "      <th>Diagnosis at Discharge (t2)</th>\n",
       "      <th>CRS-R (t2)</th>\n",
       "      <th>RLAS (t2)</th>\n",
       "      <th>DRS (t2)</th>\n",
       "      <th>ERBI A (t2)</th>\n",
       "      <th>ERBI B (t2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.380828</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>1.087012</td>\n",
       "      <td>0.673219</td>\n",
       "      <td>-0.818321</td>\n",
       "      <td>-0.585028</td>\n",
       "      <td>-0.15615</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-1.149958</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>-0.401286</td>\n",
       "      <td>2.075281</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>-0.890420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.960077</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-0.377127</td>\n",
       "      <td>0.673219</td>\n",
       "      <td>-1.074205</td>\n",
       "      <td>-0.585028</td>\n",
       "      <td>0.30551</td>\n",
       "      <td>0.381824</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>-1.171364</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>-0.498348</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.106384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.350228</td>\n",
       "      <td>-1.586582</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>0.673219</td>\n",
       "      <td>-0.946263</td>\n",
       "      <td>-0.585028</td>\n",
       "      <td>-0.15615</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>-1.171364</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>-0.732315</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>0.368701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.252690</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>0.043107</td>\n",
       "      <td>-0.84864</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>-0.251339</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.682187</td>\n",
       "      <td>-1.083264</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>1.155651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.698064</td>\n",
       "      <td>0.630286</td>\n",
       "      <td>-1.109196</td>\n",
       "      <td>-0.869890</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>0.043107</td>\n",
       "      <td>-0.84864</td>\n",
       "      <td>0.720485</td>\n",
       "      <td>1.030489</td>\n",
       "      <td>0.853706</td>\n",
       "      <td>-0.261354</td>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.080257</td>\n",
       "      <td>-0.264382</td>\n",
       "      <td>-0.452267</td>\n",
       "      <td>0.893335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age       Sex  Marshall (t0)  Entry Diagnosis (t0)  CRS-R (t1)  \\\n",
       "0  1.380828  0.630286       1.087012              0.673219   -0.818321   \n",
       "1 -0.960077  0.630286      -0.377127              0.673219   -1.074205   \n",
       "2 -1.350228 -1.586582      -1.109196              0.673219   -0.946263   \n",
       "3 -1.252690  0.630286      -1.109196             -0.869890    0.844923   \n",
       "4  0.698064  0.630286      -1.109196             -0.869890    0.844923   \n",
       "\n",
       "   RLAS (t1)  DRS (t1)  ERBI A (t1)  ERBI B (t1)  GOS-E (t1)  \\\n",
       "0  -0.585028  -0.15615    -0.295498    -0.251339    0.853706   \n",
       "1  -0.585028   0.30551     0.381824    -0.251339   -1.171364   \n",
       "2  -0.585028  -0.15615    -0.295498    -0.251339   -1.171364   \n",
       "3   0.043107  -0.84864    -0.295498    -0.251339    0.853706   \n",
       "4   0.043107  -0.84864     0.720485     1.030489    0.853706   \n",
       "\n",
       "   Diagnosis at Discharge (t2)  CRS-R (t2)  RLAS (t2)  DRS (t2)  ERBI A (t2)  \\\n",
       "0                    -1.149958    0.427507  -0.401286  2.075281     0.452267   \n",
       "1                    -0.261354    0.427507   0.682187 -0.498348     0.452267   \n",
       "2                    -0.261354    0.427507   0.682187 -0.732315     0.452267   \n",
       "3                    -0.261354    0.427507   0.682187 -1.083264     0.452267   \n",
       "4                    -0.261354    0.427507   0.080257 -0.264382    -0.452267   \n",
       "\n",
       "   ERBI B (t2)  \n",
       "0    -0.890420  \n",
       "1     0.106384  \n",
       "2     0.368701  \n",
       "3     1.155651  \n",
       "4     0.893335  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tbi5x= df_tbi5.drop('GOS-E (t2)', 1, errors='ignore')\n",
    "df_tbi5x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41fdaf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRS-R (t2)</th>\n",
       "      <th>ERBI B (t2)</th>\n",
       "      <th>DRS (t2)</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marshall (t0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.427507</td>\n",
       "      <td>-0.890420</td>\n",
       "      <td>2.075281</td>\n",
       "      <td>1.380828</td>\n",
       "      <td>1.087012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>-0.498348</td>\n",
       "      <td>-0.960077</td>\n",
       "      <td>-0.377127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.368701</td>\n",
       "      <td>-0.732315</td>\n",
       "      <td>-1.350228</td>\n",
       "      <td>-1.109196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.427507</td>\n",
       "      <td>1.155651</td>\n",
       "      <td>-1.083264</td>\n",
       "      <td>-1.252690</td>\n",
       "      <td>-1.109196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.427507</td>\n",
       "      <td>0.893335</td>\n",
       "      <td>-0.264382</td>\n",
       "      <td>0.698064</td>\n",
       "      <td>-1.109196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRS-R (t2)  ERBI B (t2)  DRS (t2)       Age  Marshall (t0)\n",
       "0    0.427507    -0.890420  2.075281  1.380828       1.087012\n",
       "1    0.427507     0.106384 -0.498348 -0.960077      -0.377127\n",
       "2    0.427507     0.368701 -0.732315 -1.350228      -1.109196\n",
       "3    0.427507     1.155651 -1.083264 -1.252690      -1.109196\n",
       "4    0.427507     0.893335 -0.264382  0.698064      -1.109196"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = [\"CRS-R (t2)\", \"ERBI B (t2)\", \"DRS (t2)\", \"Age\", \"Marshall (t0)\"]  # Replace with the names of the columns you want to select\n",
    "# Select the columns\n",
    "df_select = df_tbi5x[selected_columns]\n",
    "df_select.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9bb50b",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e064347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "svm_model = make_pipeline(SVC())\n",
    "logreg_model = make_pipeline(LogisticRegression())\n",
    "dt_model = make_pipeline(DecisionTreeClassifier())\n",
    "knn_model = make_pipeline(KNeighborsClassifier(n_neighbors=5))\n",
    "gnb = make_pipeline(GaussianNB())\n",
    "rf = make_pipeline(RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "# Create a list of models\n",
    "models = [logreg_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e730fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d5d13ce",
   "metadata": {},
   "source": [
    "### 4 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e6394f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tbi4['GOS-E (t2)'] = df_tbi4['GOS-E (t2)'].apply(lambda x: 1 if 1 <= x <= 2 else x)\n",
    "df_tbi4['GOS-E (t2)'] = df_tbi4['GOS-E (t2)'].apply(lambda x: 2 if 3 <= x <= 4 else x)\n",
    "df_tbi4['GOS-E (t2)'] = df_tbi4['GOS-E (t2)'].apply(lambda x: 3 if 5 <= x <= 6 else x)\n",
    "df_tbi4['GOS-E (t2)'] = df_tbi4['GOS-E (t2)'].apply(lambda x: 4 if 7 <= x <= 8 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c7ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_select\n",
    "#X=(df_tbi4x.iloc[:,1:]).drop(columns=[\"GOS-E (t2)\"]) # Features\n",
    "y = df_tbi4[\"GOS-E (t2)\"]   # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aefee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X before SMOTE: (102, 5)\n",
      "Shape of X after SMOTE: (152, 5)\n"
     ]
    }
   ],
   "source": [
    "#### SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Apply SMOTE to address class imbalance\n",
    "smote = SMOTE(random_state= None)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "print(f'''Shape of X before SMOTE: {X.shape}\n",
    "Shape of X after SMOTE: {X_resampled.shape}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf28a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91cbbe8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.countplot(y=y_train, data=X_train )\n",
    "sns.color_palette(\"husl\", 8)\n",
    "plt.ylabel('Level')\n",
    "plt.xlabel('Total')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3342436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    38\n",
      "4    29\n",
      "1    26\n",
      "3     9\n",
      "Name: GOS-E (t2), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a53ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c194f9a2",
   "metadata": {},
   "source": [
    "#### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "686d36b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: ['logisticregression'] - Accuracy: 0.8431372549019608, F1 Score: 0.8067780836297326\n",
      "Mean Sensitivity (Recall): 0.6968274466005864, Mean Specificity: 0.9418343321917808\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index],y.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    # Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d82640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: ['logisticregression'] - Accuracy: 0.868421052631579, F1 Score: 0.8677673788250754\n",
      "Mean Sensitivity (Recall): 0.868421052631579, Mean Specificity: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in loo.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9bdaa",
   "metadata": {},
   "source": [
    "#### k fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bfd0096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: ['logisticregression'] - Accuracy: 0.8431372549019608, F1 Score: 0.8068500127323657\n",
      "Mean Sensitivity (Recall): 0.6998638838475499, Mean Specificity: 0.9423159246575342\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index],y.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07d4c4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: ['logisticregression'] - Accuracy: 0.8421052631578947, F1 Score: 0.8412808741756109\n",
      "Mean Sensitivity (Recall): 0.8421052631578947, Mean Specificity: 0.9473684210526316\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index],y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220e8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create a model (Random Forest Classifier)\n",
    "model = RandomForestClassifier(max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200)\n",
    "\n",
    "# Perform Leave-One-Out Cross-Validation\n",
    "k_fold = KFold(n_splits=10)\n",
    "y_pred = cross_val_predict(model, X_resampled, y_resampled, cv=k_fold)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_resampled, y_pred)\n",
    "print(\"Mean Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_resampled, y_pred, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = recall_score(y_resampled, y_pred, average='weighted')\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "\n",
    "# Calculate specificity\n",
    "# Since specificity is not directly supported by sklearn, we need to calculate it manually\n",
    "# Specificity = TN / (TN + FP)\n",
    "# Where TN is True Negative and FP is False Positive\n",
    "conf_matrix = confusion_matrix(y_resampled, y_pred)\n",
    "specificity = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "print(\"Specificity:\", specificity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3773da26",
   "metadata": {},
   "source": [
    "#### GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models with their hyperparameter grids\n",
    "svm_model = make_pipeline(SVC())\n",
    "svm_param_grid = {'svc__kernel': ['linear', 'rbf']}\n",
    "\n",
    "logreg_model = make_pipeline(LogisticRegression(max_iter=1000))\n",
    "logreg_param_grid = {'logisticregression__C': [0.1, 1, 10]}\n",
    "\n",
    "\n",
    "dt_model = make_pipeline(DecisionTreeClassifier())\n",
    "dt_param_grid = {'decisiontreeclassifier__max_depth': [None, 10, 20], 'decisiontreeclassifier__min_samples_split': [2, 5, 10]}\n",
    "\n",
    "knn_model = make_pipeline(KNeighborsClassifier())\n",
    "knn_param_grid = {'kneighborsclassifier__n_neighbors': [3, 5, 7]}\n",
    "\n",
    "gnb_model = make_pipeline( GaussianNB())\n",
    "\n",
    "\n",
    "# Create a list of models with their corresponding parameter grids\n",
    "models = [\n",
    "    (logreg_model, logreg_param_grid),\n",
    "    (svm_model, svm_param_grid),\n",
    "    (dt_model, dt_param_grid),\n",
    "    (knn_model, knn_param_grid),\n",
    "    (gnb_model, {}),  # GaussianNB does not have specific hyperparameters to tune\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3685cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "# Iterate over models\n",
    "for model, param_grid in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(best_model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, (model, _) in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69ea183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "# Iterate over models\n",
    "for model, param_grid in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=k_fold, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in k_fold.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index],y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(best_model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, (model, _) in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a468f1",
   "metadata": {},
   "source": [
    "### 2 class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05635753",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tbi4['GOS-E (t2)'] = df_tbi4['GOS-E (t2)'].apply(lambda x: 1 if 1 <= x <= 4 else x)\n",
    "df_tbi4['GOS-E (t2)'] = df_tbi4['GOS-E (t2)'].apply(lambda x: 2 if 5 <= x <= 8 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cbc5f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    102\n",
      "Name: GOS-E (t2), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_tbi4['GOS-E (t2)'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4b8a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    64\n",
      "2    38\n",
      "Name: GOS-E (t2), dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df_tbi5x.values\n",
    "y = df_tbi4[\"GOS-E (t2)\"]\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c139ee88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRS (t2)</th>\n",
       "      <th>ERBI B (t2)</th>\n",
       "      <th>Age</th>\n",
       "      <th>ERBI A (t1)</th>\n",
       "      <th>RLAS (t2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.075281</td>\n",
       "      <td>-0.890420</td>\n",
       "      <td>1.380828</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>-0.401286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.498348</td>\n",
       "      <td>0.106384</td>\n",
       "      <td>-0.960077</td>\n",
       "      <td>0.381824</td>\n",
       "      <td>0.682187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.732315</td>\n",
       "      <td>0.368701</td>\n",
       "      <td>-1.350228</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>0.682187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.083264</td>\n",
       "      <td>1.155651</td>\n",
       "      <td>-1.252690</td>\n",
       "      <td>-0.295498</td>\n",
       "      <td>0.682187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.264382</td>\n",
       "      <td>0.893335</td>\n",
       "      <td>0.698064</td>\n",
       "      <td>0.720485</td>\n",
       "      <td>0.080257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DRS (t2)  ERBI B (t2)       Age  ERBI A (t1)  RLAS (t2)\n",
       "0  2.075281    -0.890420  1.380828    -0.295498  -0.401286\n",
       "1 -0.498348     0.106384 -0.960077     0.381824   0.682187\n",
       "2 -0.732315     0.368701 -1.350228    -0.295498   0.682187\n",
       "3 -1.083264     1.155651 -1.252690    -0.295498   0.682187\n",
       "4 -0.264382     0.893335  0.698064     0.720485   0.080257"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_2c = [\"CRS-R (t1)\",\"Age\",\"ERBI B (t1)\"]\n",
    "# Select the columns\n",
    "df_sel = df_tbi5x[selected_2c]\n",
    "df_sel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71b4be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_sel\n",
    "#X=(df_tbi4x.iloc[:,1:]).drop(columns=[\"GOS-E (t2)\"]) # Features\n",
    "y = df_tbi4[\"GOS-E (t2)\"]   # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e08ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73b0cf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results: [0.88888889 0.75       1.         0.875      0.875      1.\n",
      " 0.875      0.875      0.75       0.875     ]\n",
      "Mean accuracy: 0.8763888888888889\n",
      "Confusion matrix:\n",
      "[[43  6]\n",
      " [ 3 29]]\n",
      "Accuracy: 0.8888888888888888\n",
      "Sensitivity (Recall): 0.8775510204081632\n",
      "Specificity: 0.8775510204081632\n",
      "Precision: 0.9347826086956522\n",
      "F1 score: 0.9052631578947369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, cross_val_predict\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Perform 10-fold cross-validation\n",
    "cross_val_results = cross_val_score(GaussianNB(), X_train, y_train, cv=k_fold, scoring='accuracy')\n",
    "y_pred = cross_val_predict(GaussianNB(), X_train, y_train, cv=10)\n",
    "conf_mat1 = confusion_matrix(y_train, y_pred)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "# Calculate sensitivity (recall)\n",
    "sensitivity = recall_score(y_train, y_pred)\n",
    "\n",
    "# Calculate specificity\n",
    "tn, fp, fn, tp = conf_mat1.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_train, y_pred)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_train, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cross-validation results:\", cross_val_results)\n",
    "print(\"Mean accuracy:\", cross_val_results.mean())\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_mat1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Sensitivity (Recall):\", sensitivity)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Define a custom scoring function to compute sensitivity and specificity\n",
    "def sensitivity_specificity_scoring(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    return sensitivity, specificity\n",
    "\n",
    "# Create a scoring dictionary with multiple metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_score': make_scorer(f1_score, average='weighted'),\n",
    "    'sensitivity': make_scorer(sensitivity_specificity_scoring, greater_is_better=True),\n",
    "    'specificity': make_scorer(sensitivity_specificity_scoring, greater_is_better=True)\n",
    "}\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=10, scoring=scoring, refit='accuracy')\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Get the results\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Print the best parameters and scores\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "print(\"Best F1 Score:\", cv_results['mean_test_f1_score'][grid_search.best_index_])\n",
    "print(\"Best Sensitivity:\", cv_results['mean_test_sensitivity'][grid_search.best_index_])\n",
    "print(\"Best Specificity:\", cv_results['mean_test_specificity'][grid_search.best_index_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd95819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Define a custom scoring function to compute sensitivity\n",
    "def sensitivity_scoring(y_true, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    return sensitivity\n",
    "\n",
    "# Create a scoring dictionary with multiple metrics\n",
    "scoring = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'f1_score': make_scorer(f1_score, average='weighted'),\n",
    "    'sensitivity': make_scorer(sensitivity_scoring),\n",
    "}\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=10, scoring=scoring, refit='accuracy')\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "# Get the best estimator\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Get the results\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Print the best parameters and scores\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
    "print(\"Best F1 Score:\", cv_results['mean_test_f1_score'][grid_search.best_index_])\n",
    "print(\"Best Sensitivity:\", cv_results['mean_test_sensitivity'][grid_search.best_index_])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbc534a",
   "metadata": {},
   "source": [
    "#### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2374487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index],y.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a165524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in loo.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf301a58",
   "metadata": {},
   "source": [
    "#### k fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=85)\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index],y.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over models\n",
    "for model in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in kf.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index],y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445d94ea",
   "metadata": {},
   "source": [
    "#### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc5b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Use leave-one-out cross-validation for evaluation\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "# Iterate over models\n",
    "for model, param_grid in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in k_fold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(best_model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, (model, _) in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "conf_matrices = []\n",
    "\n",
    "# Define 10-fold cross-validation\n",
    "k_fold = KFold(n_splits=10)\n",
    "\n",
    "# Iterate over models\n",
    "for model, param_grid in models:\n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=k_fold, scoring='accuracy')\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # Get best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for train_index, test_index in k_fold.split(X_resampled):\n",
    "        X_train, X_test = X_resampled.iloc[train_index], X_resampled.iloc[test_index]\n",
    "        y_train, y_test = y_resampled.iloc[train_index],y_resampled.iloc[test_index]\n",
    "        \n",
    "        # Train model on training data\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred.extend(best_model.predict(X_test))\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')  # Specify average='weighted' for multiclass\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate sensitivity and specificity for each class\n",
    "    sensitivity = []\n",
    "    specificity = []\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        tp = conf_matrix[i, i]\n",
    "        fn = np.sum(conf_matrix[i, :]) - tp\n",
    "        fp = np.sum(conf_matrix[:, i]) - tp\n",
    "        tn = np.sum(conf_matrix) - tp - fn - fp\n",
    "        \n",
    "        sensitivity.append(tp / (tp + fn))\n",
    "        specificity.append(tn / (tn + fp))\n",
    "    \n",
    "    # Append mean sensitivity and specificity to lists\n",
    "    sensitivity_scores.append(np.mean(sensitivity))\n",
    "    specificity_scores.append(np.mean(specificity))\n",
    "    \n",
    "    # Append results to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Print results\n",
    "for i, (model, _) in enumerate(models):\n",
    "    print(f\"Model {i+1}: {list(model.named_steps.keys())} - Accuracy: {accuracy_scores[i]}, F1 Score: {f1_scores[i]}\")\n",
    "    print(f\"Mean Sensitivity (Recall): {sensitivity_scores[i]}, Mean Specificity: {specificity_scores[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee29ada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
